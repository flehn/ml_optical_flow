{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras.layers\n",
        "from keras import layers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, Dense, Dropout, Normalization,MaxPool2D,Flatten\n",
        "from moviepy.editor import *"
      ],
      "metadata": {
        "id": "vrEo42KxZ4zF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add9e231-e607-4118-e7a6-43d30e9f5963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3940352/45929032 bytes (8.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7634944/45929032 bytes (16.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11591680/45929032 bytes (25.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15425536/45929032 bytes (33.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19382272/45929032 bytes (42.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20447232/45929032 bytes (44.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24576000/45929032 bytes (53.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28614656/45929032 bytes (62.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32841728/45929032 bytes (71.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36741120/45929032 bytes (80.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40779776/45929032 bytes (88.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44793856/45929032 bytes (97.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "GkwR2rabsA3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.robots.ox.ac.uk/~alonso/data/tv_human_interactions_videos.tar.gz\n",
        "!wget http://www.robots.ox.ac.uk/~alonso/data/readme.txt\n",
        "!mkdir TV-HI\n",
        "!tar -xvf  'tv_human_interactions_videos.tar.gz' -C TV-HI\n",
        "!mv readme.txt 'TV-HI/readme.txt'"
      ],
      "metadata": {
        "id": "Tukat2RpsCOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_1_indices = [[2,14,15,16,18,19,20,21,24,25,26,27,28,32,40,41,42,43,44,45,46,47,48,49,50],\n",
        "                 [1,6,7,8,9,10,11,12,13,23,24,25,27,28,29,30,31,32,33,34,35,44,45,47,48],\n",
        "                 [2,3,4,11,12,15,16,17,18,20,21,27,29,30,31,32,33,34,35,36,42,44,46,49,50],\n",
        "                 [1,7,8,9,10,11,12,13,14,16,17,18,22,23,24,26,29,31,35,36,38,39,40,41,42]]\n",
        "set_2_indices = [[1,3,4,5,6,7,8,9,10,11,12,13,17,22,23,29,30,31,33,34,35,36,37,38,39],\n",
        "                 [2,3,4,5,14,15,16,17,18,19,20,21,22,26,36,37,38,39,40,41,42,43,46,49,50],\n",
        "                 [1,5,6,7,8,9,10,13,14,19,22,23,24,25,26,28,37,38,39,40,41,43,45,47,48],\n",
        "                 [2,3,4,5,6,15,19,20,21,25,27,28,30,32,33,34,37,43,44,45,46,47,48,49,50]]\n",
        "classes = ['handShake', 'highFive', 'hug', 'kiss']  # we ignore the negative class\n",
        "\n",
        "# test set\n",
        "set_1 = [f'{classes[c]}_{i:04d}.avi' for c in range(len(classes)) for i in set_1_indices[c]]\n",
        "set_1_label = [f'{classes[c]}' for c in range(len(classes)) for i in set_1_indices[c]]\n",
        "print(f'Set 1 to be used for test ({len(set_1)}):\\n\\t{set_1}')\n",
        "print(f'Set 1 labels ({len(set_1_label)}):\\n\\t{set_1_label}\\n')\n",
        "\n",
        "# training set\n",
        "set_2 = [f'{classes[c]}_{i:04d}.avi' for c in range(len(classes)) for i in set_2_indices[c]]\n",
        "set_2_label = [f'{classes[c]}' for c in range(len(classes)) for i in set_2_indices[c]]\n",
        "print(f'Set 2 to be used for train and validation ({len(set_2)}):\\n\\t{set_2}')\n",
        "print(f'Set 2 labels ({len(set_2_label)}):\\n\\t{set_2_label}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyZmog2CsDHv",
        "outputId": "af061da9-ee71-4e01-cc86-bab5e4a216da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set 1 to be used for test (100):\n",
            "\t['handShake_0002.avi', 'handShake_0014.avi', 'handShake_0015.avi', 'handShake_0016.avi', 'handShake_0018.avi', 'handShake_0019.avi', 'handShake_0020.avi', 'handShake_0021.avi', 'handShake_0024.avi', 'handShake_0025.avi', 'handShake_0026.avi', 'handShake_0027.avi', 'handShake_0028.avi', 'handShake_0032.avi', 'handShake_0040.avi', 'handShake_0041.avi', 'handShake_0042.avi', 'handShake_0043.avi', 'handShake_0044.avi', 'handShake_0045.avi', 'handShake_0046.avi', 'handShake_0047.avi', 'handShake_0048.avi', 'handShake_0049.avi', 'handShake_0050.avi', 'highFive_0001.avi', 'highFive_0006.avi', 'highFive_0007.avi', 'highFive_0008.avi', 'highFive_0009.avi', 'highFive_0010.avi', 'highFive_0011.avi', 'highFive_0012.avi', 'highFive_0013.avi', 'highFive_0023.avi', 'highFive_0024.avi', 'highFive_0025.avi', 'highFive_0027.avi', 'highFive_0028.avi', 'highFive_0029.avi', 'highFive_0030.avi', 'highFive_0031.avi', 'highFive_0032.avi', 'highFive_0033.avi', 'highFive_0034.avi', 'highFive_0035.avi', 'highFive_0044.avi', 'highFive_0045.avi', 'highFive_0047.avi', 'highFive_0048.avi', 'hug_0002.avi', 'hug_0003.avi', 'hug_0004.avi', 'hug_0011.avi', 'hug_0012.avi', 'hug_0015.avi', 'hug_0016.avi', 'hug_0017.avi', 'hug_0018.avi', 'hug_0020.avi', 'hug_0021.avi', 'hug_0027.avi', 'hug_0029.avi', 'hug_0030.avi', 'hug_0031.avi', 'hug_0032.avi', 'hug_0033.avi', 'hug_0034.avi', 'hug_0035.avi', 'hug_0036.avi', 'hug_0042.avi', 'hug_0044.avi', 'hug_0046.avi', 'hug_0049.avi', 'hug_0050.avi', 'kiss_0001.avi', 'kiss_0007.avi', 'kiss_0008.avi', 'kiss_0009.avi', 'kiss_0010.avi', 'kiss_0011.avi', 'kiss_0012.avi', 'kiss_0013.avi', 'kiss_0014.avi', 'kiss_0016.avi', 'kiss_0017.avi', 'kiss_0018.avi', 'kiss_0022.avi', 'kiss_0023.avi', 'kiss_0024.avi', 'kiss_0026.avi', 'kiss_0029.avi', 'kiss_0031.avi', 'kiss_0035.avi', 'kiss_0036.avi', 'kiss_0038.avi', 'kiss_0039.avi', 'kiss_0040.avi', 'kiss_0041.avi', 'kiss_0042.avi']\n",
            "Set 1 labels (100):\n",
            "\t['handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss']\n",
            "\n",
            "Set 2 to be used for train and validation (100):\n",
            "\t['handShake_0001.avi', 'handShake_0003.avi', 'handShake_0004.avi', 'handShake_0005.avi', 'handShake_0006.avi', 'handShake_0007.avi', 'handShake_0008.avi', 'handShake_0009.avi', 'handShake_0010.avi', 'handShake_0011.avi', 'handShake_0012.avi', 'handShake_0013.avi', 'handShake_0017.avi', 'handShake_0022.avi', 'handShake_0023.avi', 'handShake_0029.avi', 'handShake_0030.avi', 'handShake_0031.avi', 'handShake_0033.avi', 'handShake_0034.avi', 'handShake_0035.avi', 'handShake_0036.avi', 'handShake_0037.avi', 'handShake_0038.avi', 'handShake_0039.avi', 'highFive_0002.avi', 'highFive_0003.avi', 'highFive_0004.avi', 'highFive_0005.avi', 'highFive_0014.avi', 'highFive_0015.avi', 'highFive_0016.avi', 'highFive_0017.avi', 'highFive_0018.avi', 'highFive_0019.avi', 'highFive_0020.avi', 'highFive_0021.avi', 'highFive_0022.avi', 'highFive_0026.avi', 'highFive_0036.avi', 'highFive_0037.avi', 'highFive_0038.avi', 'highFive_0039.avi', 'highFive_0040.avi', 'highFive_0041.avi', 'highFive_0042.avi', 'highFive_0043.avi', 'highFive_0046.avi', 'highFive_0049.avi', 'highFive_0050.avi', 'hug_0001.avi', 'hug_0005.avi', 'hug_0006.avi', 'hug_0007.avi', 'hug_0008.avi', 'hug_0009.avi', 'hug_0010.avi', 'hug_0013.avi', 'hug_0014.avi', 'hug_0019.avi', 'hug_0022.avi', 'hug_0023.avi', 'hug_0024.avi', 'hug_0025.avi', 'hug_0026.avi', 'hug_0028.avi', 'hug_0037.avi', 'hug_0038.avi', 'hug_0039.avi', 'hug_0040.avi', 'hug_0041.avi', 'hug_0043.avi', 'hug_0045.avi', 'hug_0047.avi', 'hug_0048.avi', 'kiss_0002.avi', 'kiss_0003.avi', 'kiss_0004.avi', 'kiss_0005.avi', 'kiss_0006.avi', 'kiss_0015.avi', 'kiss_0019.avi', 'kiss_0020.avi', 'kiss_0021.avi', 'kiss_0025.avi', 'kiss_0027.avi', 'kiss_0028.avi', 'kiss_0030.avi', 'kiss_0032.avi', 'kiss_0033.avi', 'kiss_0034.avi', 'kiss_0037.avi', 'kiss_0043.avi', 'kiss_0044.avi', 'kiss_0045.avi', 'kiss_0046.avi', 'kiss_0047.avi', 'kiss_0048.avi', 'kiss_0049.avi', 'kiss_0050.avi']\n",
            "Set 2 labels (100):\n",
            "\t['handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'handShake', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'highFive', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'hug', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss', 'kiss']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert train labels into integers\n",
        "training_label_int = []\n",
        "for label in set_1_label:\n",
        "  training_label_int.append(set_2_label.index(label))\n",
        "training_labels = np.array(training_label_int)\n",
        "\n",
        "# convert test labels into integers\n",
        "testing_label_int = []\n",
        "for label in set_2_label:\n",
        "  testing_label_int.append(set_1_label.index(label))\n",
        "testing_labels = np.array(testing_label_int)\n"
      ],
      "metadata": {
        "id": "ClBDqNUusLrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OHE Labels\n",
        "labels_train = []\n",
        "for label in training_labels:\n",
        "  if label == 0:\n",
        "    labels_train.append(np.array([1,0,0,0]))\n",
        "  elif label == 25:\n",
        "    labels_train.append(np.array([0,1,0,0]))\n",
        "  elif label == 50:\n",
        "    labels_train.append(np.array([0,0,1,0]))\n",
        "  elif label == 75:\n",
        "    labels_train.append(np.array([0,0,0,1]))\n",
        "  \n",
        "labels_test = []\n",
        "for label in testing_labels:\n",
        "  if label == 0:\n",
        "    labels_test.append(np.array([1,0,0,0]))\n",
        "  elif label == 25:\n",
        "    labels_test.append(np.array([0,1,0,0]))\n",
        "  elif label == 50:\n",
        "    labels_test.append(np.array([0,0,1,0]))\n",
        "  elif label == 75:\n",
        "    labels_test.append(np.array([0,0,0,1]))\n",
        "\n",
        "labels_train = np.array(labels_train)\n",
        "labels_test = np.array(labels_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "2EpQg6P6sOO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute middle frame for Optical Flow\n",
        "\n",
        "frames_total = []\n",
        "\n",
        "for x in range(100):                                                                              #Iterate over all 100 videos...\n",
        "  clip=VideoFileClip(f'TV-HI/tv_human_interactions_videos/{set_1[x]}')                            #...extract xth clip...\n",
        "  number_of_frames = 0                                                                            #...(re-)initialise number of frames (int)\n",
        "  for frame in clip.iter_frames():                                                                #.Count number of frames...\n",
        "    number_of_frames+=1\n",
        "  middle_frame_position = int(number_of_frames/2)\n",
        "  frames_total.append(middle_frame_position)   "
      ],
      "metadata": {
        "id": "jqgDNfxosQWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optical flow\n",
        "all_flows=[]\n",
        "for i in range(100):                                                        #iterate through clips\n",
        "  clip = VideoFileClip(f'TV-HI/tv_human_interactions_videos/{set_1[i]}')    #current clip\n",
        "  int_mf = frames_total[i]                                                  #get int middle frame\n",
        "  frames = []\n",
        "  for f,frame in enumerate(clip.iter_frames()):\n",
        "    if f >= int_mf and f < int_mf+12:                                       #Collect 16 frames, measured from the middle frame onward\n",
        "      frames.append(frame)\n",
        "    if f == int_mf+12:\n",
        "      break                                                                 #If frames are collected, dont stop looping through remaining frames\n",
        "\n",
        "  prev_frame = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)                  #Init previous frame, read in grayscale, resize (because all clips can have somewhat different shapes)\n",
        "  prev_frame = cv2.resize(prev_frame, (30,40))     \n",
        "\n",
        "  flows = []\n",
        "  for frame_int in range(1,12):\n",
        "    curr_frame = cv2.cvtColor(frames[frame_int], cv2.COLOR_BGR2GRAY)        #Read current frame in grayscale, resize\n",
        "    curr_frame = cv2.resize(curr_frame, (30,40))\n",
        "\n",
        "    flow = cv2.calcOpticalFlowFarneback(prev_frame,curr_frame, None, 0.5, 3, 15, 3, 7, 1.2, 0) \n",
        "                              #Compute optical flow, convert to colors to see optical flow in colors (which aids learning)\n",
        "\n",
        "    np.reshape(flow, (30,40,2))\n",
        "    flows.append(flow)                                                       #Save this image's opticical flow\n",
        "    prev_frame = curr_frame\n",
        "  \n",
        "  stack = np.stack(flows,axis=2)                                                  #Create single stack of images and save it: before hstack(flows)\n",
        "  all_flows.append(stack)                                                 #Create single stack of images and save it\n",
        " \n"
      ],
      "metadata": {
        "id": "-4QKPFslsSL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Validation split\n",
        "#shape (176, 3432, 2)\n",
        "train_images_new=[];validation_images_new=[];train_labels_new=[]; validation_labels_new =[] \n",
        "for x in range(0,100,10):\n",
        "  train_images_new.append(all_flows[x:x+9])        #append index 0 up until 9 to training...\n",
        "  validation_images_new.append(all_flows[x+9])     #...append index 9 to validation\n",
        "\n",
        "  train_labels_new.append(labels_train[x:x+9])\n",
        "  validation_labels_new.append(labels_train[x+9])\n",
        "\n",
        "\n",
        "of_train_labels = np.array(train_labels_new); of_train_images=np.array(train_images_new)\n",
        "\n",
        "of_validation_labels = np.array(validation_labels_new); of_validation_images = np.array(validation_images_new)\n",
        "del train_images_new,train_labels_new,validation_images_new,validation_labels_new               #Del temporary variables\n"
      ],
      "metadata": {
        "id": "3XT7eVa_sawR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(of_train_images.shape, \"\", of_train_labels.shape, \"\", of_validation_images.shape, \"\", of_validation_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xRerPP6sdHN",
        "outputId": "1eb36039-81ea-4fd4-b2bc-88e3f8cb1cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 9, 40, 30, 11, 2)  (10, 9, 4)  (10, 40, 30, 11, 2)  (10, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "of_train_images = np.reshape(of_train_images, (90,40,30,22))\n",
        "of_train_labels = np.reshape(of_train_labels,(90, 4))\n",
        "of_validation_images = np.reshape(of_validation_images, (10,40,30,22))"
      ],
      "metadata": {
        "id": "cRV4_skksetV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(of_train_images.shape, \"\", of_train_labels.shape, \"\", of_validation_images.shape, \"\", of_validation_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3adzMfjsg2r",
        "outputId": "7ed0f707-225b-4a31-ef55-88d29bef3bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90, 40, 30, 22)  (90, 4)  (10, 40, 30, 22)  (10, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model2 TF"
      ],
      "metadata": {
        "id": "65v_TP1ts9HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the middle frame of each train video:\n",
        "training_images_fromvideo = []\n",
        "for x in range(100):\n",
        "  clip=VideoFileClip(f'TV-HI/tv_human_interactions_videos/{set_1[x]}')\n",
        "  frame = clip.get_frame(clip.duration/2)\n",
        "  #image = tf.image.convert_image_dtype(frame, tf.float32) # equivalent to dividing image pixels by 255\n",
        "  image = tf.image.resize(frame, (40,30))\n",
        "  training_images_fromvideo.append(image)\n",
        "training_images_fromvideo = np.array(training_images_fromvideo)\n",
        "training_images_fromvideo = training_images_fromvideo.astype('float32')"
      ],
      "metadata": {
        "id": "sv18zB9CshTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_new=[]; validation_images_new=[]; train_labels_new=[]; validation_labels_new =[]   #Temporary variables\n",
        "\n",
        "for x in range(0,100,10):\n",
        "  #print(x,\":\",x+9)\n",
        "  train_images_new.append(training_images_fromvideo[x:x+9])        #append index 0 up until 9 to training...\n",
        "  train_labels_new.append(labels_train[x:x+9])\n",
        "  \n",
        "  #print(\"x:\",x+9)\n",
        "  validation_images_new.append(training_images_fromvideo[x+9])     #...append index 9 to validation\n",
        "  validation_labels_new.append(labels_train[x+9])\n",
        "\n",
        "\n",
        "tf_train_labels = np.array(train_labels_new); tf_train_images=np.array(train_images_new)\n",
        "tf_validation_labels = np.array(validation_labels_new); tf_validation_images = np.array(validation_images_new)\n",
        "del train_images_new,train_labels_new,validation_images_new,validation_labels_new               #Del temporary variables\n",
        "print(\"train_images: \", tf_train_images.shape, \"train_labels: \", tf_train_labels.shape,\"validation_labels: \", tf_validation_labels.shape, \"validation_images: \", tf_validation_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBI7vpAytIQv",
        "outputId": "4138ac44-be9d-4fe9-cda1-78d611e9caf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images:  (10, 9, 40, 30, 3) train_labels:  (10, 9, 4) validation_labels:  (10, 4) validation_images:  (10, 40, 30, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_images = np.reshape(tf_train_images, (90,40,30,3))\n",
        "tf_train_labels = np.reshape(tf_train_labels,(90, 4))\n",
        "print(tf_train_images.shape, \"\", tf_train_labels.shape, \"\", tf_validation_images.shape, \"\", tf_validation_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVo5ckh5vDTi",
        "outputId": "7bb48f4a-49b8-47f9-dd8b-d1a6fca9d7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90, 40, 30, 3)  (90, 4)  (10, 40, 30, 3)  (10, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained Models\n",
        "Import both Pretrained Model and freeze the weights so that they cant get updated"
      ],
      "metadata": {
        "id": "JiO3UlhF-xu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh2KGXDeAUfG",
        "outputId": "101caf21-a009-4037-b5e3-0343a2835b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Open both Models\n",
        "\n",
        "#TRANSFERED MODEL\n",
        "tf_model = keras.models.load_model(\"/content/drive/MyDrive/Assignment5/Model_for_TVHITransferLearning5.2\")\n",
        "tf_model = tf.keras.Model(inputs=tf_model.input, outputs=tf_model.layers[-2].output, name=\"TF-Model\")\n",
        "#transfered_learned_model.trainable = False # prevents the weights in a given layer from being updated during training\n",
        "tf_model.summary()\n",
        "\n",
        "#OPTICAL FLOW\n",
        "of_model = keras.models.load_model(\"/content/drive/MyDrive/Assignment5/Model_opticalFlow\")\n",
        "of_model = tf.keras.Model(inputs=of_model.input, outputs=of_model.layers[-2].output, name=\"OF-Model\")\n",
        "#of_model.trainable = False # prevents the weights in a given layer from being updated during training\n",
        "of_model.summary()"
      ],
      "metadata": {
        "id": "2F59q0nr-6tG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1665c9ba-0ab5-4824-fd7d-6c462b154560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"TF-Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 40, 30, 3)]       0         \n",
            "                                                                 \n",
            " rescaling_11 (Rescaling)    (None, 40, 30, 3)         0         \n",
            "                                                                 \n",
            " sequential_4 (Sequential)   (None, 40, 30, 3)         0         \n",
            "                                                                 \n",
            " model_17 (Functional)       (None, 160)               438400    \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 512)               82432     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 520,832\n",
            "Trainable params: 520,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"OF-Model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22_input (InputLayer  [(None, 40, 30, 22)]     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 38, 28, 32)        6368      \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 36, 26, 32)        9248      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 36, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 34, 24, 32)        9248      \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 32, 22, 32)        9248      \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 22528)             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               11534848  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,568,960\n",
            "Trainable params: 11,568,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jgWc5itCCuL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV-2Ik_kfxmV"
      },
      "source": [
        "# New two-stream Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New Model (Instead of Sequential we use functional API)\n",
        "\n",
        "input_tf_model = tf.keras.Input(shape=(40, 30, 3))\n",
        "input_of_model = tf.keras.Input(shape=(40, 30, 22))\n",
        "\n",
        "transfered_features = tf_model(input_tf_model, training=True)\n",
        "of_features = of_model(input_of_model, training=True)\n",
        "\n",
        "#Concatenate both models\n",
        "x = layers.concatenate([transfered_features, of_features])\n",
        "#x = tf.keras.layers.GlobalAveragePooling2D()(x) # addintionaly flattens the input \n",
        "x = layers.Dense(64, activation='relu', kernel_regularizer='l1_l2')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(64, activation='relu', kernel_regularizer='l1_l2')(x)\n",
        "\n",
        "outputs = Dense(4, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs=[input_tf_model, input_of_model], outputs=outputs, name=\"2stream_model\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "C5D2y1p3qolJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b18ab78-1a95-4a4a-ce7c-cc5a47f29ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"2stream_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 40, 30, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 40, 30, 22)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " TF-Model (Functional)          (None, 512)          520832      ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " OF-Model (Functional)          (None, 512)          11568960    ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 1024)         0           ['TF-Model[2][0]',               \n",
            "                                                                  'OF-Model[2][0]']               \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 64)           65600       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64)           0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 64)           4160        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 4)            260         ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 12,159,812\n",
            "Trainable params: 12,159,812\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 5:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)"
      ],
      "metadata": {
        "id": "_CXrZWm7zNFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tf_train_images: \", tf_train_images.shape, \"tf_train_labels: \", tf_train_labels.shape,\"tf_validation_labels: \", tf_validation_labels.shape, \"validation_images: \", tf_validation_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwGwADD9Bi-S",
        "outputId": "cd62a43c-e887-4a2b-c4ee-739e80fbcfc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf_train_images:  (90, 40, 30, 3) tf_train_labels:  (90, 4) tf_validation_labels:  (10, 4) validation_images:  (10, 40, 30, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tf_train_images: \", of_train_images.shape, \"of_train_labels: \", of_train_labels.shape,\"of_validation_labels: \", of_validation_labels.shape, \"validation_images: \", of_validation_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tf43dXeCR-q",
        "outputId": "52fe72fd-be07-49ab-c0c9-f0ca6b55aefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf_train_images:  (90, 40, 30, 22) of_train_labels:  (90, 4) of_validation_labels:  (10, 4) validation_images:  (10, 40, 30, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=.001),metrics=['accuracy'],loss='categorical_crossentropy')\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "history = model.fit(x=[tf_train_images, of_train_images], y=tf_train_labels, validation_data=([tf_validation_images, of_validation_images], tf_validation_labels), epochs=30, batch_size=10, callbacks=[callback])"
      ],
      "metadata": {
        "id": "Dtkh3fTqzj6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "V4Wxi0y-Zfr9",
        "outputId": "f3a0e733-3ff2-4672-a783-af5ed81f8ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "X1NJaqB4Zu4K",
        "outputId": "a7ebc558-3b9c-491e-e719-b7e267eb398a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/Assignment5/Two-Stream-Model\")"
      ],
      "metadata": {
        "id": "EpYKdAdMn3sB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "1755a30a-4f47-439c-db14-4c2e3d2ca030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-c3894cfbc317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Assignment5/Two-Stream-Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9YB8CiUPLu3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the middle frame of each train video:\n",
        "training_images_fromvideo = []\n",
        "for x in range(100):\n",
        "  clip=VideoFileClip(f'TV-HI/tv_human_interactions_videos/{set_2[x]}')\n",
        "  frame = clip.get_frame(clip.duration/2)\n",
        "  #image = tf.image.convert_image_dtype(frame, tf.float32) # equivalent to dividing image pixels by 255\n",
        "  image = tf.image.resize(frame, (40,30))\n",
        "  training_images_fromvideo.append(image)\n",
        "training_images_fromvideo = np.array(training_images_fromvideo)\n",
        "training_images_fromvideo = training_images_fromvideo.astype('float32')\n",
        "\n",
        "# Compute middle frame for Optical Flow\n",
        "\n",
        "frames_total_test = []\n",
        "\n",
        "for x in range(100):                                                                              #Iterate over all 100 videos...\n",
        "  clip=VideoFileClip(f'TV-HI/tv_human_interactions_videos/{set_2[x]}')                            #...extract xth clip...\n",
        "  number_of_frames = 0                                                                            #...(re-)initialise number of frames (int)\n",
        "  for frame in clip.iter_frames():                                                                #.Count number of frames...\n",
        "    number_of_frames+=1\n",
        "  middle_frame_position = int(number_of_frames/2)\n",
        "  frames_total_test.append(middle_frame_position)   \n",
        "\n",
        "\n",
        "#Optical flow\n",
        "all_flows_test=[]\n",
        "for i in range(100):                                                        #iterate through clips\n",
        "  clip = VideoFileClip(f'TV-HI/tv_human_interactions_videos/{set_2[i]}')    #current clip\n",
        "  int_mf = frames_total_test[i]                                                  #get int middle frame\n",
        "  frames = []\n",
        "  for f,frame in enumerate(clip.iter_frames()):\n",
        "    if f >= int_mf and f < int_mf+12:                                       #Collect 16 frames, measured from the middle frame onward\n",
        "      frames.append(frame)\n",
        "    if f == int_mf+12:\n",
        "      break                                                                 #If frames are collected, dont stop looping through remaining frames\n",
        "\n",
        "  prev_frame = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)                  #Init previous frame, read in grayscale, resize (because all clips can have somewhat different shapes)\n",
        "  prev_frame = cv2.resize(prev_frame, (30,40))     \n",
        "\n",
        "  flows = []\n",
        "  for frame_int in range(1,12):\n",
        "    curr_frame = cv2.cvtColor(frames[frame_int], cv2.COLOR_BGR2GRAY)        #Read current frame in grayscale, resize\n",
        "    curr_frame = cv2.resize(curr_frame, (30,40))\n",
        "\n",
        "    flow = cv2.calcOpticalFlowFarneback(prev_frame,curr_frame, None, 0.5, 3, 15, 3, 7, 1.2, 0) \n",
        "                              #Compute optical flow, convert to colors to see optical flow in colors (which aids learning)\n",
        "\n",
        "    np.reshape(flow, (30,40,2))\n",
        "    flows.append(flow)                                                       #Save this image's opticical flow\n",
        "    prev_frame = curr_frame\n",
        "  \n",
        "  stack = np.stack(flows,axis=2)                                                  #Create single stack of images and save it: before hstack(flows)\n",
        "  all_flows_test.append(stack)                                                 #Create single stack of images and save it\n",
        " \n",
        "test_data = np.array(all_flows_test)"
      ],
      "metadata": {
        "id": "ONJXpNSnLtKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "of_test_data = np.reshape(test_data, (100,40,30,22))\n",
        "tf_test_data = training_images_fromvideo"
      ],
      "metadata": {
        "id": "8WiKR5xvNl-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = model.evaluate([tf_test_data, of_test_data], labels_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqTzuNCQMDOh",
        "outputId": "95d3c2ad-9c66-4a10-b57e-773b3c9d3b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 39ms/step - loss: 7.2638 - accuracy: 0.2900\n"
          ]
        }
      ]
    }
  ]
}